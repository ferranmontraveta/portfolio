{"data":{"allContentfulProject":{"edges":[{"node":{"id":"c078d469-403e-5683-8864-2568d0745359","title":"PDB FOR A UAV","miniTags":["STARTUP","ELECTRONICS"],"miniDescription":{"miniDescription":"Designed and manufactured a Power Distribution Board for an Unmanned Aerial Vehicle. This work was done within the startup Venturi Unmanned Vehicles."},"extTags":"TAGS: STARTUP, ELECTRONICS","extTech":"TECHNOLOGIES: ALTIUM DESIGNER","extPeople":"PEOPLE: Ferran Montraveta Roca","extDescription":{"childContentfulRichText":{"html":"<h4>Introduction</h4><p>As in every BSc degree, I had to conclude it by doing a final project or thesis. At that point, I had been studying electronics and automatic control, and even though I started to fall in love more with the software part of things, I decided to keep an open mind when choosing a topic.</p><p>To prevent me from rushing I started looking for opportunities way before the deadline. It was the summer before the last year of my BSc when a university-based startup reached students over email offering thesis positions. After the recommendation from a friend, I decided to try my luck and go interview for them. The proposed thesis consisted of designing and possibly developing a Power Distribution Board (PDB) for an Unmanned Aerial Vehicle (UAV). As I liked the idea of seeing how is life in a startup I decided to accept.</p><h4>The startup</h4><p>The startup with which I worked is¬†<a href=\"http://venturi-utech.com/en/\">Venturi Unmanned Technologies</a>. The business of this startup is to develop a fast, robust, and simple UAV that can perform tasks such as surveillance and maintenance in big areas. As an example, the drone can inspect power grids with its thermal and visual sensors. The company has recently put together the first model of the UAV and they are partnering up with the¬†<a href=\"http://www.esa.int/ESA\">European Space Association</a>¬†(ESA).</p><h4>Project</h4><p>As per my part, as mentioned before I was assigned to try and design the first approach of a PDB for the drone. During this process, several challenges were encountered, some technical and some others due to the nature of an early-stage startup. As the company was just starting to ideate and design the machine, there were several changes in terms of motors and payloads. Due to this, the PDB design had to be re-adapted several times throughout my work.</p><p>In terms of technical challenges, originally the UAV had to be powered from a hydrogen battery. The idea was to use hydrogen so that the machine would not have to be charged every time, which takes time, but just fill the tank with fuel and at the same time not have CO2 emissions. Finally, this power source was discarded due to its complexity for the first MVP.¬†</p><p>Once the power source was fixed to LiPo batteries and the payloads aboard the aircraft were selected, we were able to start designing the PDB. Because of the nature of LiPo batteries and the requirements of the components on the plane, we distinguished between four different voltages. Due to the nature of the payloads, we needed to escalate the DC voltage given by the LiPo batteries to three different DC voltages.</p><p>At this point, discussing with the professor on how to tackle it, we decided to go with DC-DC converter boards already in the market, as designing three flyback converters with high efficiency would take a lot of time and would be out of the scope for a BSc student.</p><p>Once everything seemed to fall into place, we encountered other technical issues, the ones related to the environment in which the PDB would be in. The board was going to be inside the chassis of the plane and had to be as flexible as possible. On the other hand, we encountered the problem of how to dissipate the heat generated by the converters without much space in the aircraft&#39;s body.</p><p>Overall, it was a nice though stressful experience in which I finally learned, hands-on, how to apply many of the concepts taught during the BSc.</p>"}},"images":[{"fluid":{"src":"//images.ctfassets.net/b6lrqzvm884p/7lFsp7PM3egAy5RFCSHQFR/6d706a988fe56fd5572a0a7231f4dfc1/maxresdefault.jpg?w=800&q=50"}},{"fluid":{"src":"//images.ctfassets.net/b6lrqzvm884p/61WFljHeTRx3ODwp7Z2k8v/185603d32aa7dfc7ac35481aa795bf20/venturi-background.jpg?w=800&q=50"}}]}},{"node":{"id":"67d236dd-565c-55e3-9c84-8f1be6e94bff","title":"UNIFORM","miniTags":["STARTUP","BUSINESS IDEA"],"miniDescription":{"miniDescription":"An inter-university platform where exchange students give feedback on their experience. The goals were to boost exchange students in the EU and, potentially, globally."},"extTags":"TAGS: STARTUP, BUSINESS IDEA","extTech":"TECHNOLOGIES: AXURE, ADOBE PREMIERE PRO","extPeople":"PEOPLE: Waliyah Saqhani, Thor Galle, Jiachang Watson, Luke Ball, Krishnananda Pramudita, and Ferran Montraveta","extDescription":{"childContentfulRichText":{"html":"<h4>Longer description coming soon! :)</h4><p></p>"}},"images":[{"fluid":{"src":"//images.ctfassets.net/b6lrqzvm884p/1NwTmC2Z6ddkmsxDaNRiGS/f4f035b4aa90fae22589fa0a30aa4099/Uniform_Pitch_6.png?w=800&q=50"}}]}},{"node":{"id":"83aed6cb-52af-5490-bbd8-106bee0614a2","title":"PORTFOLIO","miniTags":["WEB","FRONT-END"],"miniDescription":{"miniDescription":"Own project that served as an excuse to dive into web developing. The end result is, obviously, this very same website."},"extTags":"TAGS: WEB, FRONT-END","extTech":"TECHNOLOGIES: GATSBY, REACT, CONTENTFUL, CSS, HTML","extPeople":"PEOPLE: Ferran Montraveta Roca","extDescription":{"childContentfulRichText":{"html":"<p>During summer 2019, I decided that I wanted to learn the basics of web programming. When I was in high school I did come across some HTML and CSS coding, but I had no idea how to tackle modern and fast websites. On the other hand, I usually need a higher purpose that drives me to keep learning and improving so I started thinking about some projects I could do. In the end, I thought that coding my own portfolio website would be both a good motivation to make me stick with the learning process, and in the end, it would also have a good purpose.</p><p>Once I knew I wanted to create my portfolio, I decided to do a crazy design session in which I would let myself go and design what I thought would be a cool portfolio. To give form to this ideation process, I searched for free mock-up programs and found Adobe XD. You can check the look of that mock-up¬†here. As you can appreciate, the idea was to do it horizontally as if it were a huge canvas.</p><p>After the ideation/design phase, I moved on to the technology I would choose to build it. During the past year, I had heard about Angular from a friend that seemed to love it. I first took a look at it and decided I could search for some other state-of-the-art technologies, and here is where I ran into¬†<a href=\"https://reactjs.org/\">React JS</a>. For some reason, when I saw react, I decided I wanted to go with it, so I started to learn and play around with the basics of it. At a very early stage, another friend of mine said she had been checking something called¬†<a href=\"https://www.gatsbyjs.org/\">Gatsby JS</a>¬†for static sites for a very cool project she was working on at her job.</p><p>Finally, once I locked down that I wanted to do my portfolio with Gatsby JS and React JS, I started developing each of the slides of the big horizontal canvas. In the beginning, I started approaching the horizontal scroll by overflowing the X-axis on a bigger div with Flexbox. Even though I achieved the move that I wanted, talking with some Human-Computer Interaction Design friends they informed me on how making it horizontal would not be natural for the user. At that time I agreed, but my opinion was that I could make it very logical and natural within the first page. As I achieved the horizontal scroll by overflow, the mouse wheel was not scrolling. This made me rethink the horizontal scroll as it would not feel that natural if the user could not use the wheel. In the end, I abandoned the horizontal scroll idea due to these downsides and the fact that I did not have enough time at the moment to pursue it. This is the reason why the current version has a vertical scroll.</p><p>Moreover, when I was halfway through the first iteration of coding I discovered a template called¬†<a href=\"https://github.com/EmaSuriano/gatsby-starter-mate\">Mate</a>. By analyzing the code I saw I was doing plenty of things the wrong way, so I started redoing all the code by using the same structure as in Mate. As some say:</p><p>&quot;The most ignorant one will always be the happiest one.&quot;</p><p>This definitely applied to me in this case. By checking the implementation of Mate, I saw a lot of cool features I did not even know they existed. In the end, as I was porting to a similar structure, I started importing some of the components directly from Mate. After integrating them, I reworked the majority of them to make them a bit more mine.</p><p>Another very interesting thing that I started implementing after seeing Mate was the use of a CMS to manage the content. Being very honest I never stopped to think that these things existed (they fall a bit far from my studies till the moment üòÖ) and when I saw it I just knew I had to use it. After some improvised introduction to¬†<a href=\"https://graphql.org/\">GraphQL</a>, I managed to link my portfolio with¬†<a href=\"https://www.contentful.com/\">Contentful</a>, where I have all the content.</p><p><b>Work To Do:</b></p><ul><li><p>I have not given up on the horizontal scroll</p></li><li><p>Substitute the education and work experience sections in the About section for a timeline.</p></li><li><p>Block scroll from happening when a project modal is open.</p></li></ul><p>Please let me know what do you like and dislike about this website on¬†<a href=\"https://ferranmontraveta.typeform.com/to/qaXwzo\">this form</a>!</p>"}},"images":[{"fluid":{"src":"//images.ctfassets.net/b6lrqzvm884p/6D6HZXKxzP4LZcmh3jRGkN/1f5c021ff3fad2388adcd8404dca9467/addthis-react-flux-javascript-scaling.png?w=800&q=50"}},{"fluid":{"src":"//images.ctfassets.net/b6lrqzvm884p/26m7tyC04EgwgBdOaTvzg3/24f220252ec9afd7bf143ccd475bd956/gatsby.jpg?w=800&q=50"}},{"fluid":{"src":"//images.ctfassets.net/b6lrqzvm884p/yDTbd2NHBlthugXU46gvp/57245efe67ad741f220e76ea151ee9bb/landing.png?w=800&q=50"}},{"fluid":{"src":"//images.ctfassets.net/b6lrqzvm884p/5D67BFFOAj3dPT7LpXov1n/9994708e39f5631c0e898397baeb3f7d/projects.png?w=800&q=50"}}]}},{"node":{"id":"4a1e47bf-1baf-50f1-8bf3-bd404d260d88","title":"WORKOUT RECOGNITION","miniTags":["RESEARCH","AI","STARTUP"],"miniDescription":{"miniDescription":"Work on how to automatically recognize different workout exercises and perform repetition counting using CNNs. The result of this work is a paper that was presented at IWANN 2019 in Gran Canaria."},"extTags":"TAGS: STARTUP   BUSINESS   IDEA","extTech":"TECHNOLOGIES: AXURE   ADOBE PREMIERE PRO","extPeople":"PEOPLE: Kacper Skawinski and Ferran Montraveta","extDescription":{"childContentfulRichText":{"html":"<p>During my first year of MSc, at Aalto University, I took the course¬†<a href=\"https://www.aalto.fi/en/teaching-lab/machine-learning-for-mobile-and-pervasive-systems-p\">Machine Learning for Mobile and Pervasive Systems</a>. The course was project-based, which means that apart from the lectures the grade would depend on a project that we would be doing in parallel.</p><p>To do this project, Kacper Skawinski (a fellow EIT student) and I teamed up. To choose the project topic, the professor in charge had some suggestions for us students. After giving it a look and finding some of them really interesting, we decided that it was not worth it to enter a dispute with other teams to get the ones that we wanted to we decided to give ourselves a chance to come up with a topic. After some days of casual brainstorming, we came up with the idea of, using an IMU placed on a person, to be able to recognize what type of exercise was the subject performing. We also thought it would be nice to tell how many repetitions was the user doing and, originally, also at what pace (to check the level of tiredness) and if they were doing it the correct way.</p><p>After receiving the approval from the professor we started with it. As Kacper had already worked with some specific sensors, we decided to go with them. So MoveSensor it was!</p><p>Once we had decided on a sensor, we went on and performed some research to see what the state-of-the-art was. We came across some interesting papers, but none of them were using CNN to recognize different workout exercises. The most similar work we found used an SVM approach.</p><p>To start defining our work, we first fixed the amount of data that we would collect and what type of data. Obviously, we would be gathering data from an IMU, but did we really need the gyro and the magnetometer as well? We decided to frame our work only using the accelerometer readings. On the other hand, we had to define how many types of exercises we would perform the work with, so we agreed on four: push-ups, pull-ups, jumping jacks, and squats. It was time to collect the data!</p><p>To collect the data we started searching for people (friends üôÉ) that would be willing to perform the workout routine with the sensor while being recorded. In the end, we managed to gather 10 subjects. But that was not it, as all Machine Learning Engineer knows, we need to label the data before we can start using it (for supervised learning methods). So there we were, hand labeling all the data that we had collected.</p><p>Finally, after all the labeling we could start doing what we were there to do, design the CNN that would identify what workout exercise is the subject doing. We developed all our code and we trained the models in¬†<a href=\"https://colab.research.google.com\">Google Colab</a>. After several tries, we came up with a fairly lightweight architecture that performed quite well within the training-test datasets, and generalized good with unseen data.</p><p>The final results yielded an accuracy of 90.6% over test data and 89.9% over validation data.</p><p>After we presented our work at the end of the course, we were approached by professor¬†<a href=\"https://people.aalto.fi/stephan.sigg\">Stephan Sigg</a>¬†with a proposal to rewrite our report into a paper so that we could try to get accepted at a conference. We gladly agreed, and with the help of prof. Sigg and¬†<a href=\"https://people.aalto.fi/rainhard.findling\">Dr. Findling</a>¬†we put together a new scientific paper. We submitted it to IWANN 2019 and we got accepted. After that, I traveled to the conference in Gran Canaria and presented the paper. You can find the slides for the presentation <a href=\"https://docs.google.com/presentation/d/16K8acO0utabERe_IhjpREbvvpv3GSHSEYnGt7BU6XDk/edit?usp=sharing\">here</a>.</p><p>In August 2019 we received a positive message from the organizers and a proposal to extend our work for a new journal that would be published.</p>"}},"images":[{"fluid":{"src":"//images.ctfassets.net/b6lrqzvm884p/BUGyneYw8BxzFwSUN2PPb/3791ee3ddc639e78730842361b984fe9/sensor.jpg?w=800&q=50"}},{"fluid":{"src":"//images.ctfassets.net/b6lrqzvm884p/4F9dFdJB8EoILf38v3Swgk/46b0946e103eaa48419c3ed53055bfcb/sensor_strap.jpeg?w=800&q=50"}},{"fluid":{"src":"//images.ctfassets.net/b6lrqzvm884p/3HlNBbuBVRu2HbYmx7yPsm/9efea52ad2892b21f7f36b8349d03cbb/architecture3.png?w=800&q=50"}},{"fluid":{"src":"//images.ctfassets.net/b6lrqzvm884p/2ScvUgoBqxNJkj5himrcru/a4d5412f695ce9598570c85b877e7cc2/confusion_matrixnorm_clean.png?w=800&q=50"}}]}},{"node":{"id":"10b2e9ee-3365-55da-9670-77315cceee2f","title":"SLAM","miniTags":["RESEARCH","AI","ROBOTICS"],"miniDescription":{"miniDescription":"In this work, I did the whole setup from scratch of a mobile robot to perform mapping tasks by fusing lidar and an IMU. This work was done during a Research Assistant summer internship at Aalto University with professor Arno Solin."},"extTags":"TAGS: RESEARCH, AI, ROBOTICS","extTech":"TECHNOLOGIES: RASPBERRY PI 3, PYTHON, SLAMTECH A1 LIDAR, AltIMU-10 v5 (IMU)","extPeople":"PEOPLE: Ferran Montraveta Roca","extDescription":{"childContentfulRichText":{"html":"<p><b>Introduction</b></p><p>In May 2019 I started a summer internship at Aalto University as Research Assistant. In specific, I joined¬†<a href=\"https://users.aalto.fi/~asolin/\">Dr. Arno Solin‚Äôs</a>¬†Machine Learning research group. During this period I put together a bill of materials, assembled an RC car, integrated an IMU and a lidar, and finally coded all the software to fuse all these sensors and perform mapping tasks.</p><p>¬†</p><p><b>Work</b></p><p>It all started with an idea the professor had. He wanted to buy an RC car controlled by a Raspberry Pi and equip it with several sensors to, using sensor fusion, perform various tasks, such as mapping.</p><p>Once we had chosen the base RC car, the¬†<a href=\"https://www.piborg.org/blog/monsterborg-overview\">Monsterborg</a>¬†developed by PiBorg, I was in charge to put together a bill of materials (BOM) of specific sensors and needed gear to assemble the car with all its payloads. The required sensors where: a camera, an IMU and a lidar. As all of these sensors would have to be controlled and powered by the Raspberry Pi, we had to pick carefully the models that were suitable and compatible. After some research we ended up choosing:</p><ul><li><p>Camera -¬†<a href=\"https://www.raspberrypi.org/products/camera-module-v2/\">Camera Module V2 (Raspberry)</a></p></li><li><p>IMU - <a href=\"https://www.pololu.com/product/2739\">Altimu10v5 by Pololu</a></p></li><li><p>Lidar -¬†<a href=\"https://www.slamtec.com/en/Lidar/A1\">RPLidar A1 by Slamtech</a></p></li></ul><p>Finally, when all the material arrived, I assembled the base car itself and tested it. Once the basic was working, I started incorporating the sensors one by one. First I tested the camera, which was very simple as the original product already counts on the possibility to add one. The next sensor I incorporated was the IMU. It had to be connected to the RPi through the I2C pins on the GPIO, and the correspondent power pins. In order to fetch the data from the sensor, there was already a python library that I utilized. To achieve the sampling frequency needed for the future applications I had to modify some of the configuration values that the python script was sending to the sensor and also I had to compile the library to C for more speed. Finally, it was the turn of the lidar. After building a whole structure on top of the robot so that the lidar would have a clear view on its plane, I was able to incorporate it. Once the lidar was in place, I utilized an unofficial library to fetch the data.</p><p>Once all the sensors were working individually, I put together a script that would fetch all the data and mark it with a timestamp on coded a CSV file that would be later used to perform the mapping tasks offline.</p><p>Finally, when this script was working, I was able to start playing around with the gathered data to perform a first approach on mapping. We would use the odometry of the wheels to know how much did the robot advance, and then with the IMU, we would know what was the exact angle in which the robot was oriented in the XY plane. To do that, we used the accelerometer (gravity) to calibrate the orientation of the IMU so that then we could extract the angular velocity at each timestamp and then integrate to know the actual orientation in degrees. Once the location part was settled, it was time to fuse the lidar data with it. Simply, we took the lidar point-cloud at every timestamp and plotted it with respect to world coordinates using rotation and translation matrices.¬†</p><p>The final result can be seen in one of the videos below in this post. The final &quot;drift&quot; we have is not due to the use of the data, but due to the capabilities of the RPi 3 on-board. When using it in short sessions it usually performs well, but when the session is longer in time there were moments in which it was overflown and would stop recording data. When this was happened while the robot was turning, of course, the gyro integration would not be correct (missing steps in the middle), and when integrating the final orientation is not correct.</p><p></p><p><b>Possible Future Work</b></p><ul><li><p>Substitute the RPi 3 B+ for the newest RPi 4</p></li><li><p>Optimize the script that fetches the data for the new RPi</p></li><li><p>Implementation of an online code that sends the data in real-time from the RPi to a more powerful computer</p></li><li><p>Definitely improve the localization with more advanced techniques</p></li><li><p>Improve the mapping by applying more advanced techniques like Probabilistic Machine Learning to be more accurate when driving through the same spot several times</p></li></ul><p></p>"}},"images":[{"fluid":{"src":"//images.ctfassets.net/b6lrqzvm884p/7pxzPImW14xYW3ZzOwq8U3/f6d060e8bfec6cf3051382dda74f2b99/car.png?w=800&q=50"}},{"fluid":{"src":"//images.ctfassets.net/b6lrqzvm884p/7GBS8LQVSO3784OOjN8Dox/35b97378fbc79cf813a288894ea24778/IMG_20190722_112954.jpg?w=800&q=50"}},{"fluid":{"src":"//images.ctfassets.net/b6lrqzvm884p/1sPkzumVlYiwZEmicYAD2O/09af8f6fc83046e47866412dd552176b/ezgif.com-video-to-gif.gif?w=800&q=50"}},{"fluid":{"src":"//images.ctfassets.net/b6lrqzvm884p/IdVQvCG4KBmUX8RLf3k6b/dbac794c5ebda2b3ede64207cb48c2f8/ezgif.com-video-to-gif__1_.gif?w=800&q=50"}}]}},{"node":{"id":"16a0af8c-e6b2-502c-a91b-0ff8706e516b","title":"SALUD","miniTags":["HACKATHON","BUSINESS IDEA"],"miniDescription":{"miniDescription":"An app that reminds the user to go for specific checks with the doctor based on what the user might be in danger of contracting. With this project, we won two prizes at the Nordics Health Hackathon 2019 held in Reykjavik."},"extTags":"TAGS: HACKATHON, BUSINESS IDEA","extTech":"TECHNOLOGIES: FLUTTER, ANDROID STUDIO","extPeople":"PEOPLE: Waliyah Sahqani, Naima Volz, Javier Benitez Fernandez, Kacper Skawinski, and Ferran Montraveta","extDescription":{"childContentfulRichText":{"html":"<p><b>Background</b></p><p>By 2030, the Nordics want to be the most sustainable and integrated health region in the world, providing the best possible personalized health care for all its citizens. To engage people living in the Nordics to work together towards this goal, the Nordic Health Hackathon powered by Nordic Innovation was organized during two weekends in two Nordic capitals: Reykjavik and Helsinki. Our team participated in the event in Reykjavik to contribute to a balanced participant audience from all over the Nordics.</p><p>The aim of the Nordic Health Hackathon was to engage people living in the Nordics to improve health and quality of life for Nordic citizens by creating a healthy supportive environment based on innovative patient-facing digital solutions.¬†</p><p>For this purpose, we were provided medical data by Icelandic Directorate of Health, various self-collected data such as social media usage, physical activity (FitBit) or Music usage (Spotify) provided by digi.me as well as financial data by Arion Banki.\n</p><p><b>Participation</b></p><p>Our solution¬†<b>Salud</b>¬†enables humans to track, interpret and manage their personal health. Salud tackles two challenges: Firstly, European citizens often do not use their free preventive medical check-ups. Secondly, even though 70% of people in the Nordics believe they have (very) good health, they track it and want to be in control, they possess a wrong self-diagnosis. 50% are obese and most citizens too inactive.¬†</p><p>In order to make people aware that they should take active steps towards managing their health - even though they might currently feel well - and also make use of their privilege of free medical health check-ups, we created Salud, a personal health management application. Salud makes it easy for the patient to analyze his (already self-collected) lifestyle data, report it back to the doctor, keep track of vaccination and book prescriptions and appointments.</p><p>Our developed mobile app retrieves real medical data, current activity data (e.g. FitBit) and credit card transaction categories to give individuals health check-up and vaccination recommendations, view and order medical prescriptions and book doctor appointments. These will allow users to actually make use of all this data that they collect themselves or have already to meaningfully improve their healthcare. As an example, a strong increase in sleep (FitBit data), a reduction in the workout time and/or higher heart rate within shorter workout time (FitBit data), a decreased weight (self-reported data) and an increase in food purchases (credit card transaction data) might indicate Diabetes Type 1. The app would then flag this potentially critical profile, suggest a doctor appointment and allow the user to book it straight from the app.¬†¬†</p><p>To develop this application, we used data about vaccinations, appointments, prescriptions provided by the Iceland Health Ministry, Fitbit data provided through digi.me and credit card transaction data from Arion Banki.</p><p>Salud won the Arion Banki challenge as the best ‚Äúnovel use of financial data to help people lead healthier, happier lives‚Äù and was selected as runner-up in digi.me challenge. We were the only team that was acknowledged in two different challenges.\n</p><p><b>Learning Outcomes</b></p><p>For me, the Nordic Health Hackathon was the first over-night software development hackathon I participated in. The experience itself was very valuable as I practiced to prioritize tasks, manage time, and take tough decisions with confidence under time constraints and high pressure.</p><p>Secondly, we were provided with a wide range of datasets and a broad challenge: ‚ÄúImprove the health care in the Nordics‚Äù. We understood that a great application should not only consist of functional code but tackle a meaningful problem. We used our knowledge of looking at the user‚Äôs problem first, ideating solutions, creating a storyboard and user-centered design, and then develop the application. We learned how to implement this approach in a very short timeframe of 24 hours.</p><p>Thirdly, we practiced splitting work in a multi-disciplinary team. First, we split into a development and design team with the developers retrieving the data from the APIs and experimenting with the output while the designers were putting together the screens. While most of us were coding through the night Naima as a non-developer could take some rest and prepare the pitch as we were aware that presenting our solution well was very important too. We thus learned how to make use of everyone‚Äôs unique skill set and quickly split work to have everyone contribute.¬†</p><p>From the technology perspective, for most of us, it was the first project we were working with Flutter - an environment for mobile application development. Nevertheless, after a few hours of hacking each person from the development team was able to work on its own and execute specific tasks precisely and accurately. Therefore, participation in the hackathon allowed us to have a quick and effective introduction to programming in Flutter that could be used in our further work.¬†</p>"}},"images":[{"fluid":{"src":"//images.ctfassets.net/b6lrqzvm884p/1PJUk06yGaW65XVt0p9KYd/a9af837cdc311b802f4b8074a5469da2/salud1.png?w=800&q=50"}},{"fluid":{"src":"//images.ctfassets.net/b6lrqzvm884p/5xcIF8fYk9NniOe8YYrRTV/5bb5c1e4cdf72aeeb7154ca6888ac7dd/salud2.png?w=800&q=50"}},{"fluid":{"src":"//images.ctfassets.net/b6lrqzvm884p/yLtwrXJxqcOLiqmudUM74/a4ac26caa93c49504de02d8e21a4cae9/FB_IMG_1553462379399.jpg?w=800&q=50"}},{"fluid":{"src":"//images.ctfassets.net/b6lrqzvm884p/4Rrrqzhi7S1G2VzK4I5ZWa/d42eb9c286869b521d0fd62d741df539/kacpnme.jpg?w=800&q=50"}},{"fluid":{"src":"//images.ctfassets.net/b6lrqzvm884p/6SP7nVr54xZxw3E4xlNIqU/69d46ca840fb0103d5f5177f638bc487/IMG-20190324-WA0014.jpg?w=800&q=50"}},{"fluid":{"src":"//images.ctfassets.net/b6lrqzvm884p/4MdhJxJun4Nk1TOxCc6tQI/05e5c613e708227e786dc0bc143bf085/win.jpg?w=800&q=50"}}]}}]}}}